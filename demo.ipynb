{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T06:25:10.517919Z",
     "start_time": "2019-09-19T06:25:08.905007Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse, io, stats\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(name, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def get_train_item(size=1024):\n",
    "    train_sample_index = np.random.randint(0, high=len(train_item_u), size=size)\n",
    "    user = train_item_u[train_sample_index]\n",
    "    pos = train_item_i[train_sample_index]\n",
    "    neg = np.random.choice(range(item_shape), size, replace=True)\n",
    "    for i in range(size):\n",
    "        item = train_item[user[i]].nonzero()[1]\n",
    "        while neg[i] in item:\n",
    "            neg[i] = np.random.choice(range(item_shape))\n",
    "    return user, pos, neg\n",
    "\n",
    "def get_train_bundle(size=1024):\n",
    "    train_sample_index = np.random.randint(0, high=len(train_bundle_u), size=size)\n",
    "    user = train_bundle_u[train_sample_index]\n",
    "    pos = train_bundle_b[train_sample_index]\n",
    "    neg = np.random.choice(range(bundle_shape), size, replace=True)\n",
    "    for i in range(size):\n",
    "        bundle = train_bundle[user[i]].nonzero()[1]\n",
    "        while (neg[i] in bundle) or (len(bundle_item[neg[i]].nonzero()[1]) == 0):\n",
    "            neg[i] = np.random.choice(range(bundle_shape))\n",
    "    return user, pos, neg\n",
    "\n",
    "def measure(user, K=3):\n",
    "    recall = 0\n",
    "    hit = 0\n",
    "    MAP = 0\n",
    "    zero = 0\n",
    "    for u in user:\n",
    "        pos = test_bundle[u].nonzero()[1]\n",
    "        neg = negative[u]\n",
    "        pos_val = pred_test_bundle(u, pos)\n",
    "        rank = 0\n",
    "        for n in neg:\n",
    "            neg_val = pred_test_bundle(u, [n])\n",
    "            if neg_val > pos_val:\n",
    "                rank += 1\n",
    "            if rank >= K:\n",
    "                break\n",
    "        if rank < K:\n",
    "            recall += 1\n",
    "            MAP += 1 / (rank + 1)\n",
    "    return (recall / len(user)), (MAP / len(user))\n",
    "    \n",
    "def get_hit():\n",
    "    Recall, MAP = measure(all_user, 5)\n",
    "    print (\"Recall: \", Recall, \"MAP: \", MAP)\n",
    "    \n",
    "def pred_test_bundle(u, bid):\n",
    "    be = []\n",
    "    w = []\n",
    "    for i, b in enumerate(bid):\n",
    "        sample = bundle_item[b].nonzero()[1]\n",
    "        bi = item_embeds[sample]\n",
    "        w = F.softmax(torch.sum(user_embeds[[u] * len(sample)] * A[sample], 1, True), 0)\n",
    "        be.append(torch.sum(bi * w, 0) + bundle_embeds[b])\n",
    "    be = torch.stack(be)\n",
    "    return dam(torch.cat((user_embeds[[u]], be), 1), True)\n",
    "    \n",
    "def pred_bundle(u, bid):\n",
    "    be = []\n",
    "    w = []\n",
    "    for i, b in enumerate(bid):\n",
    "        sample = bundle_item[b].nonzero()[1]\n",
    "        bi = item_embeds[sample]\n",
    "        w = F.softmax(torch.sum(user_embeds[[u[i]] * len(sample)] * A[sample], 1, True), 0)\n",
    "        be.append(torch.sum(bi * w, 0) + bundle_embeds[b])\n",
    "    be = torch.stack(be)\n",
    "    return dam(torch.cat((user_embeds[[u]], be), 1), True)\n",
    "\n",
    "def get_bundle_loss():\n",
    "    u, pb, nb = get_train_bundle()\n",
    "    upb = pred_bundle(u, pb)\n",
    "    unb = pred_bundle(u, nb)\n",
    "    return -torch.sum(torch.log(torch.sigmoid(upb - unb)))\n",
    "\n",
    "\n",
    "def get_item_loss():\n",
    "    u, p, n = get_train_item()\n",
    "    u = user_embeds[[u]]\n",
    "    p = item_embeds[[p]]\n",
    "    n = item_embeds[[n]]\n",
    "    \n",
    "    up = torch.cat((u, p), 1)\n",
    "    un = torch.cat((u, n), 1)\n",
    "    \n",
    "    up = dam(up)\n",
    "    un = dam(un)\n",
    "    \n",
    "    return -torch.sum(torch.log(torch.sigmoid(up - un)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T06:25:10.836773Z",
     "start_time": "2019-09-19T06:25:10.520760Z"
    }
   },
   "outputs": [],
   "source": [
    "user_item = load_obj('data/Youshu/user_item')\n",
    "user_bundle = load_obj('data/Youshu/user_list')\n",
    "bundle_item = load_obj('data/Youshu/list_item')\n",
    "\n",
    "test_item, train_item = load_obj('data/Youshu/test_item'), load_obj('data/Youshu/train_item')\n",
    "test_bundle, train_bundle = load_obj('data/Youshu/test'), load_obj('data/Youshu/train')\n",
    "negative = load_obj('data/Youshu/neg')\n",
    "train_item_u, train_item_i = train_item.nonzero()\n",
    "train_bundle_u, train_bundle_b = train_bundle.nonzero()\n",
    "\n",
    "user_shape, item_shape = user_item.shape\n",
    "bundle_shape, item_shape = bundle_item.shape\n",
    "all_user, _ = np.nonzero(np.sum(test_bundle, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T06:25:10.871747Z",
     "start_time": "2019-09-19T06:25:10.838818Z"
    }
   },
   "outputs": [],
   "source": [
    "embed_shape = 5\n",
    "user_embeds = Variable(torch.FloatTensor(user_shape, embed_shape).normal_(0, 0.001), requires_grad=True)\n",
    "item_embeds = Variable(torch.FloatTensor(item_shape, embed_shape).normal_(0, 0.001), requires_grad=True)\n",
    "bundle_embeds = Variable(torch.FloatTensor(bundle_shape, embed_shape).normal_(0, 0.001), requires_grad=True)\n",
    "\n",
    "A = Variable(torch.FloatTensor(item_shape, embed_shape).normal_(0, 0.001), requires_grad=True)\n",
    "\n",
    "class DAM(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DAM, self).__init__()\n",
    "        self.sdense = torch.nn.Linear(embed_shape * 2, embed_shape * 2)\n",
    "        self.dense = torch.nn.Linear(embed_shape * 2, embed_shape * 2)\n",
    "        self.ipred = torch.nn.Linear(embed_shape * 2, 1)\n",
    "        self.bpred = torch.nn.Linear(embed_shape * 2, 1)\n",
    "        \n",
    "    def forward(self, x, bundle=False):\n",
    "        x = torch.relu(self.sdense(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = torch.relu(self.dense(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        if bundle:\n",
    "            x = torch.relu(self.bpred(x))\n",
    "            return x\n",
    "        x = torch.relu(self.ipred(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                               | 501/800 [16:14<3:22:42, 40.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.5932782682996297 MAP:  0.3906484382417172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                          | 601/800 [21:18<2:17:06, 41.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.599544289376246 MAP:  0.39711383271622563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                     | 701/800 [26:20<1:08:34, 41.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.5955568214183993 MAP:  0.3981154466913511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 800/800 [29:06<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.5998291085160923 MAP:  0.40353650431975713\n"
     ]
    }
   ],
   "source": [
    "dam = DAM()\n",
    "dam.train()\n",
    "para = list(dam.parameters())\n",
    "para.extend([user_embeds, item_embeds, bundle_embeds, A])\n",
    "opt = torch.optim.Adam(para, lr=0.005, weight_decay=0.001)\n",
    "for epoch in tqdm(range(800)):\n",
    "    loss = get_item_loss()\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    loss = get_bundle_loss()\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    if (epoch % 100 == 0 and epoch > 400):\n",
    "        dam.eval()\n",
    "        get_hit()\n",
    "        dam.train()\n",
    "        \n",
    "dam.eval()\n",
    "get_hit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
